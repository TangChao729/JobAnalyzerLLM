{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='144.134.10.154', port=8888): Max retries exceeded with url: /search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x74e75005a7c0>: Failed to establish a new connection: [Errno 111] Connection refused'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             conn = connection.create_connection(\n\u001b[0m\u001b[1;32m    175\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             httplib_response = self._make_request(\n\u001b[0m\u001b[1;32m    704\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    397\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m                 \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mheaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"User-Agent\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_default_user_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTTPConnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1331\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1279\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSocketError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             raise NewConnectionError(\n\u001b[0m\u001b[1;32m    187\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Failed to establish a new connection: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x74e75005a7c0>: Failed to establish a new connection: [Errno 111] Connection refused",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    490\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m             retries = retries.increment(\n\u001b[0m\u001b[1;32m    788\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_pool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacktrace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='144.134.10.154', port=8888): Max retries exceeded with url: /search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x74e75005a7c0>: Failed to establish a new connection: [Errno 111] Connection refused'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_118209/2640457790.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m }\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Content-Type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdummy_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \"\"\"\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    585\u001b[0m         }\n\u001b[1;32m    586\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 587\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    563\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='144.134.10.154', port=8888): Max retries exceeded with url: /search (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x74e75005a7c0>: Failed to establish a new connection: [Errno 111] Connection refused'))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = 'http://144.134.10.154:8888/search'\n",
    "dummy_query = {\n",
    "    \"query\": {\n",
    "        \"description\": \n",
    "        '''\n",
    "        Software engineer with expertise in deep learning and cloud technologies. Graduate from the University of Melbourne with a master’s degree in IT and an outstanding academic records. Skilled in research and development in the cutting-edge AI models, especially in computer vision. Experienced in implementing AI solutions from major providers into existing software. Recognized for keen problem-solving skills and can-do attitude.\n",
    "\n",
    "        Vision HQ                                                                                                                                    Brisbane, QLD\n",
    "        SOFTWARE ENGINEER INTERN                                                                              Dec 2022 – Dec 2023\n",
    "        Developed and CI/CD deep learning models to solve specific business tasks.\n",
    "        Processed in-house data and construct optimized data pipelines to feed ML models.\n",
    "        Collaborated with software engineers on production systems and applications.\n",
    "\n",
    "        Generative AI job analyzing and matching system                               Feb 2024 – May 2024\n",
    "        #Large Language Model #Natural Language Processing\n",
    "        Leading the prototyping of a Gen-AI tool designed to provide job seekers with insights of demanding qualifications on individual resume.\n",
    "        Integrating GPT API and retrieval-augmented generation to use most up-to-date data.\n",
    "\n",
    "        Targeted billboard advertising system                                                    Jan 2024 – Mar 2024\n",
    "        #Machine Learning #Computer Vision\n",
    "        Developed an XGBoost ML model to predict ad effectiveness using real-time demographic data from digital billboard footage.\n",
    "        Retrieved attributes from video footage data into tabular data for enhanced analytics and model training.\n",
    "        Integrated computer vision (Azure Cognition) techniques to analyze crowd compositions.\n",
    "\n",
    "        Computer vision road monitoring system \t\t                         Jan 2023 – Dec 2023\n",
    "        #Computer Vision #Cloud Computing\n",
    "        Finetuned open-source computer vision models using in-house dataset, to provide tailored solution of road safety applications for smarter road management solutions.\n",
    "        Orchestrated the design, development, and testing of workflows optimized for cloud.\n",
    "        Implemented a seamless model pipeline on Google Cloud Platform, encompassing the entire spectrum from data ingestion to delivering actionable insights.\n",
    "\n",
    "        Research project for national bushfire satellite images                       Aug 2023 – Nov 2023\n",
    "        #Image Segmentation #Pattern Recognition\n",
    "        Led the evaluation of advanced CV models on satellite bushfire imagery analysis, to aid bushfire emergency planning in semi-real time.\n",
    "        Modified a ViT model to process multi-spectral imagery, resulting in 88% F1-score.\n",
    "        Research paper in-depth insights well received, under review for publication.\n",
    "\n",
    "        Full-stack web app for residents' sentiment analysis.                           Feb 2023 – Jun 2024\n",
    "        #Distributed and Parallel System #Natural Language Processing\n",
    "        Led the web app development to facilitate the analysis of residents’ satisfaction.\n",
    "        Construed frontend and backend services using React and Flask.\n",
    "        Automated deployment and scaling by utilizing Docker Swarm and Ansible.\n",
    "\n",
    "        University of Melbourne \t\t\t\t\t                                       Melbourne, VIC\n",
    "            Master of Information Technology (AI major)\t                                            Jan 2022 – Nov 2023\n",
    "            WAM:                  83/100, Graduate with Distinction\n",
    "            Core Courses:     Natural Language Processing                Computer Vision\n",
    "                                Algorithm and Complexity                     Cluster and Cloud Computing\n",
    "            Awards:               Dean’s Honours List  2022  & 2023\n",
    "                                        Melbourne Graduate Scholarship 2022\n",
    "        '''\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers={\"Content-Type\": \"application/json\"}, data=json.dumps(dummy_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mJSONDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_118209/2039760581.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;31m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m             \u001b[0;31m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRequestsJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "pprint.pprint(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['hits', 'query', 'limit', 'offset', 'processingTimeMs'])\n"
     ]
    }
   ],
   "source": [
    "print(response.json().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.json()['hits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1th job description: X is Alphabet’s moonshot factory. We are a diverse group of inventors and entrepreneurs who build and launch technologies that aim to improve the lives of millions, even billions, of people. Our goal: 10x impact on the world’s most intractable problems, not just 10% improvement. We approach projects that have the aspiration and riskiness of research with the speed and ambition of a startup. About The Team Tidal is a team at X working on a moonshot to protect the ocean and preserve its ability to support life and help feed humanity, sustainably. Our initial area of focus is on developing hardware and software technologies that bring greater visibility and understanding of what’s happening under the water. Learn more about Project Tidal . About The Role Project Tidal is looking for a software engineer to design critical applications using machine learning and computer vision models for real world use cases, working closely with customers and partners to deploy solutions. This is an opportunity to work end to end with revolutionary hardware, real world customer applications, and cutting edge technologies. If you love to work on challenging and real world problems, please apply! How You Will Make 10X Impact Design and implement applications using machine learning and computer vision models to find solutions for real world problems.Develop hybrid enterprise applications with solid API support.Work closely with customers and partners to simplify solutions.Build insights to help customers visualize and analyze the trend to further optimize their business. What You Should Have Bachelor's degree in Computer Science, a related technical field involving software/systems engineering, or equivalent practical experience.4+ years of software development experience.Strong programming skills (preferred Golang, C++ or Python).Solid data analysis and troubleshooting skills.Experience in developing large scale cloud applications using APIs and developer platforms.Excellent communication skills. I'd Be Great If You Also Have These Experience working with IoT and/or sensors.Knowledge of ML models and pipelines.Experience working with large enterprise customers.\\n\\n2th job description: We are looking for a Principal Software Engineer with deep learning leadership experience to join our group! Come join NVIDIA's AI/AV Infrastructure team to develop state of the art MLOps infrastructure for our advanced autonomous driving platform. Together, we will help advance NVIDIA's capacity to build and deploy leading solutions for a broad range of AI-based applications.  To ensure that our fleet of autonomous vehicles scalably record, analyze, and train our state-of-the-art machine learning models, we need to stay a step ahead of our engineering partners. We need someone who has built systems that handle petabyte-scale datasets, or is able to map their prior experience to develop systems that handle such scale. We are either directly involved or in collaboration with our partner teams in all the data lifecycle activities. To ensure we deliver on the expectations of our customers, our solutions must be scalable and performant. Our approach must embrace engineering and operational excellence practices across the stack. We need someone who can ensure that the primitives which make our platform build, scale, and ship reliably. You will embed in one of our engineering teams that has high visibility and work on both product-focused and infrastructure roles.  What You'll Be Doing  Contributing to the development of Deep Learning software infrastructure for large scale image and video processing tasks and leading major technical projects for the team. The range of applications you'll work on includes automotive driver assistance, autonomous navigation, and robotics.Be a part of a dynamic product and customer-oriented team. Your expertise, creativity and leadership will help bring the future of self-driving cars to our doorsteps.Be responsible for data modeling, schema design, dataset curation, search, and discovery  What We Need To See  10+ years of relevant work experience in high performance/distributed computing, including technical leadership experience.3+ years of relevant experience in productizing deep learning systems.You have a BS or MS in Computer Science, Electrical Engineering, or equivalent experience.Experience with MLOps platforms such as Flyte, MLFlow, or similar.Experience with any of the deep learning frameworks: PyTorch, Tensorflow, Keras, or similar.Proven track record to architect and develop data-first, production machine learning pipelines that scale out to very large datasets.Track record of elevating teams and increasing their velocity by helping others.Experience mentoring junior developers.Good understanding of highly parallel compute, storage, and software architectures.Experience working with multi-node/distributed training, data loading and image/video processing.Excellent communication and organization skills.Self-motivation, outstanding collaboration with peers and users, customer focused mindset.  Ways To Stand Out Of The Crowd  Previous experience of scaling up and optimizing HPC, computer vision or deep learning training pipelines to terabyte scale datasets is a huge plus.Experience with Go Lang, C++ and CUDA.Contributions to open-source DNN frameworks.Prior experience using machine learning or neural networks to tackle problems in image or video analysis.  NVIDIA is widely considered to be one of the technology world’s most desirable employers. We have some of the most forward-thinking and hardworking people on the planet working for us. If you're creative, passionate and self-motivated, we want to hear from you! NVIDIA is leading the way in groundbreaking developments in Artificial Intelligence, High-Performance Computing and Visualization. The GPU, our invention, serves as the visual cortex of modern computers and is at the heart of our products and services.  The base salary range is 268,000 USD - 414,000 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.  You will also be eligible for equity and benefits .  NVIDIA accepts applications on an ongoing basis.   NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.  \\n\\n3th job description: JOB TITLE: Big Data ArchitectLOCATION: Auburn Hills, MIJOB DESCRIPTION: Pay rate: $74.60 Location: Auburn Hills, MI OR Herndon, VAWorker Type: Fixed MonthlyEnhanced PTO/Holidays SRe-Classified to HybridMust be local to Auburn Hills, MI or Herndon, VA Important Requirements• 3+ years of hands-on implementation experience working with a combination of the following technologies: JavaScript, React, Data Java Based Solutions (API / Batch), Java REST APIs.• Experience building web services (SOAP/Rest) using Java APIs and tools, such as JAX-RPC• Experience with the Spring Framework and general MVC• 5+ years’ programming/scripting languages Java  The Big Data Developer will be responsible for the design and build of world class high-volume real-time data ingestion and processing frameworks and advanced analytics on big data platforms. He/She will research, develop, optimize, and innovate frameworks and patterns for enterprise scale data analysis and computations as part of our Big Data, Connected Car and Internet of Things initiatives. • Work as an integrated member of the technology team and drive cross functional international Big Data initiatives from beginning to end: build relationships with partner teams and stakeholders in Germany and the US, distill and present key insights in support of decision making • Design and Build world class high-volume real-time data ingestion and processing frameworks and advanced analytics on big data platforms. • Research, develop, optimize, and innovate frameworks and patterns for enterprise scale data analysis and computations as part of our Big Data, Connected Car and Internet of Things initiatives. • Lead the implementation of Hadoop platform strategy development by creating architectureblueprints, validating designs and providing recommendations on the enterprise platform strategic roadmap • Present technology solutions to senior leadership in Germany and the US in verbal, visual, and written media and influence architecture decisions that will lead the transformation of our Connected Car analytics platform and IT overall. • 3+ years of hands-on implementation experience working with a combination of the following technologies: JavaScript, React, Data Java Based Solutions (API / Batch), Java REST APIs. • 3+ years experience in designing and implementing big data solutions. This includes creating the requirements analysis, design of the technical architecture, design of the application design and development, testing, and deployment of the proposed solution • Research the tool market, follow new research streams and build partnerships with start-ups, universities and local communities • Experience building web services (SOAP/Rest) using Java APIs and tools, such as JAX-RPC • Experience with the Spring Framework and general MVC frameworks Education Requirements: A Bachelors degree in Computer science engineering or related field Qualifications• 5+ years programming/scripting languages Java• 2+ years of experience of developing solutions in cloud environments (Azure, AWS etc) with focus on analytics stack.• 2+ years of experience in big data streaming frameworks, data processing and real-time ingestion patterns.• Experience working with and evaluating open source technologies and demonstrated ability to make objective choices• Experience architecting highly scalable, highly concurrent and low latency systems• Experience scaling applications to processing multiple petabytes• Knowledge of software/data design methods, data structures, and modeling standards Nice to have: Knowledge of Chef scripting, Docker containers• Working Experience with continuous integration and continuous delivery tools• Experience with multiple cloud computing platforms• Experience with more than one data streaming technologies• Ability to communicate complex architectures and insights in a clear, precise, and actionable manner Benefit offerings include medical, dental, vision, term life insurance, short-term disability insurance, additional voluntary benefits, commuter benefits and 401K plan. Our program provides employees the flexibility to choose the type of coverage that meets their individual needs. Available paid leave may include Paid Sick Leave, where required by law; any other paid leave required by Federal, State or local law; and Holiday pay upon meeting eligibility criteria.Disclaimer: These benefit offerings do not apply to client-recruited jobs and jobs which are direct hire to a client Equal Opportunity Employer/Veterans/DisabledNot available on a C2C or C2H basisTo read our Candidate Privacy Information Statement, which explains how we will use your information, please visit https://www.modis.com/en-us/candidate-privacy/ The Company will consider qualified applicants with arrest and conviction records.\\n\\n4th job description: Calling all AWS-focused Data Engineers! Do you have skills in Redshift and Glue? Or a BI background in Quicksight? We are hiring for multiple positions to make an impact with an Amazon Premier Partner and their clients. Engineers do not need to have all qualifications to apply, Redshift and Glue or Quicksight are experience required.  QualificationsAWS Certified Big Data – SpecialtyExperience with Amazon QuickSight, Amazon API Gateway, and RedshiftStrong proficiency in programming languages such as Python, Java, or Scala, with expertise in data processing frameworks and libraries (e.g., Spark, Hadoop, SQL, etc.)In-depth knowledge of database systems (relational and NoSQL), data modeling, and data warehousing conceptsProficiency in designing and implementing ETL processes and data integration workflows using tools like Apache Airflow, Informatica, or TalendFamiliarity with data governance practices, data quality frameworks, and data security principlesAdvanced knowledge and technical proficiency with ETL, cloud-based data warehousing, and Apache Spark.Strong knowledge of AWS-specific services, including Lake Formation, Amazon Aurora, Amazon Data Pipeline, Amazon Athena, Glue, Amazon S3, Amazon DynamoDB, Amazon Relational Database Service (RDS), Amazon Elastic Map Reduce (EMR), Amazon Kinesis, Database Migration Services, etc.Familiarity and understanding of Common Data Engineering tools like: Apache Spark, Apache Airflow, Apache Lite, Apache Kafka, dbt, great_expectations·Bachelor's or master's degree in computer science, Engineering or a related field\\n\\n5th job description: X is Alphabet’s moonshot factory. We are a diverse group of inventors and entrepreneurs who build and launch technologies that aim to improve the lives of millions, even billions, of people. Our goal: 10x impact on the world’s most intractable problems, not just 10% improvement. We approach projects that have the aspiration and riskiness of research with the speed and ambition of a startup. About The Team Tidal is a team at X working on a moonshot to protect the ocean and preserve its ability to support life and help feed humanity, sustainably. Our initial area of focus is on developing hardware and software technologies that bring greater visibility and understanding of what’s happening under the water. Learn more about Project Tidal . About The Role As an Applied Machine Learning Software Engineer at Tidal, you will be working alongside other software engineers, perception experts, and research scientists to develop and deploy state-of-the-art methods to create a platform leveraging perception and machine learning to solve humanity’s biggest problems — from food production to renewable energy to climate change — by sustainably utilizing the ocean. Your role will be to enable developers to run ML workflows smoothly and efficiently. You will develop sustainable, scalable solutions to ensure the reliability and performance of these ML workflows, improve engineer productivity and ultimately help advance our Perception and ML Platform. If you love getting tech to work on challenging, real world problems, please apply! How You Will Make 10X Impact Work with our customers to understand the problem space, run experiments, collect data, and design novel and breakthrough ML solutions Profile ML performance at both model level and system level, identify performance bottlenecks and optimization opportunitiesImprove and streamline large-scale machine learning workflows for training and inference by analyzing, understanding, and fixing bottlenecksEnable better component-wise testing of training workflowsAutomate data upload/processing/training/evaluating/deploying/optimizing pipelines and develop monitoring and notification tooling to track statistics of the pipelines, improving debuggability and introspection into these complex workflowsRespond to and resolve emergent problems in production; test ML training pipelines; write software and build automation to prevent problem recurrenceKeep track of major changes and trends in infrastructure and enable adoption of new frameworks and systems without significant impact on development workEngage in capacity planning, quota management, and demand forecasting for ML workflowsCollaborate with stakeholder teams to implement and evolve large-scale Machine Learning infrastructure What You Should Have BS degree in Computer Science or a related field, or equivalent practical experienceStrong programming skills in Python and/or C++Expertise in data structures, algorithms and complexity analysis.Experience designing, analyzing, and troubleshooting large-scale distributed systems, especially enterprise cloud services (e.g., GCP, AWS)Experience with ML platforms, solutions, and infrastructure deployed to solve real world problems It’d Be Great If You Also Had These Experience with C++ and/or GoExperience with TensorFlow or PytorchExperience with SQL or similar, and parallel data processing pipelines (e.g. Flume, Apache Beam)Expertise in architecting and deploying machine learning pipelines at scaleExpertise in getting ML models into productionFamiliarity with state-of-the-art ML models for perception/computer vision tasksCustomer-facing experience creating software solutionsMS or PhD degree in Computer Science or a related field, or equivalent practical experience\\n\\n6th job description: The Qualtrics XM Platform™ is a system of action that helps businesses to attract customers who stay longer and buy more, to engage and empower employees to do the best work of their lives, to develop breakthrough products people love, and to build a brand people can’t imagine living without. Joining Qualtrics means becoming part of a team bold enough to chase breakthrough experiences - like building a technology that will be a force for good. A team committed to diversity, equity, and inclusion because of a conviction that every voice holds value, with a vision for representation that matches the world around us and inclusion that far exceeds it. You could belong to a team whose values center on transparency, being all in, having customer obsession, acting as one team, and operating with scrappiness. All so you can do the best work of your career. We believe every interaction is an opportunity. Are we yours? At Qualtrics, we create software the world’s best brands use to deliver exceptional frontline experiences, build high-performing teams, and design products people love. But we are more than a platform—we are the creators and stewards of the Experience Management category serving over 18K clients globally. Building a category takes grit, determination, and a disdain for convention—but most of all it requires close-knit, high-functioning teams with an unwavering dedication to serving our customers. When you join one of our teams, you’ll be part of a nimble group that’s empowered to set aggressive goals and move fast to achieve them. Strategic risks are encouraged and complex problems are solved together, by passing the mic and iterating until the best solution comes to light. You won’t have to look to find growth opportunities—ready or not, they’ll find you. From retail to government to healthcare, we’re on a mission to bring humanity, connection, and empathy back to business. Join over 6,000 people across the globe who think that’s work worth doing. Software Engineer - Intern Why We Have This Role As a software engineer at Qualtrics, you will be building systems to help our customers both understand and respond to the experience data provided by their customers or employees. Designing systems in an agile environment to withstand hyper growth and owning quality from end to end is a rewarding challenge and one of the reasons Qualtrics is such an exciting place to work! How You’ll Find Success Strong level of curiosityAbility to create trust in customers and teams through thorough communicationTakes initiative and shows scrappiness in getting things doneProven ability to work well in teams - partnering with managers, cross functional teams, and teammatesTakes analytical mindset to approach problems and find solutionsShows desire to learn new skills and grow in the role How You’ll Grow Develop the ability to build scalable, fast, robust, and simple SaaS solutions.Develop familiarity with containerization and full-stack development.Learn to implement new functionality from provided requirements and specifications.Benefit from working with other engineers, tech-ops, and product managersLearn Agile methodologies by attending daily stand-up meetings, prioritizing tasks, and working with a sense of urgency to meet a scheduled plan to deliver value to our customers Things You’ll Do You'll own a project. It will push you out of your comfort zone, and you'll see meaningful growth as a result.Design distributed, low latency services for ingesting, processing, and aggregating dataBuild integrations with SaaS leaders like Slack, Salesforce, and TableauCreate analytics that identify trends and sentiment in free-form text data using natural language processing and machine learningBuild widgets for visualizing data in dashboards and reportsDevelop an integrated ticketing platform that allows organizations to close the loop on customer feedbackBuild world-class survey editing and survey taking experiences What We’re Looking For On Your Resume Currently studying for a degree in Computer Science, Software Engineering, or Computer EngineeringExperience with Web-related technologies including HTML/CSS and JavaScriptExperience with JavaScript frameworks including angular or nodeExperience with modern programming languages (Java, PHP, Scala)Database / Data Storage experience (SQL / MySQL)Strong level of curiosityMust be legally authorized to work in job location without Qualtrics sponsorship now or in the futureAvailable for a 12 week internship during summer of 2024 What You Should Know About This Team Our team is a collection of extremely passionate engineers who are riding the cutting edge of cloud computing and web scalability. We organize and sort terabytes of data and develop solutions that are used by millions of users every day. We design tools that make sophisticated research simple. Few teams offer such amazing learning opportunities and possibilities for advancement like the Qualtrics Engineering team. Our Team’s Favorite Perks and Benefits Relocation and financial support for housing.We like to retain our high performers. In fact, 85% of our interns receive an offer to return full time after graduation.ExeQtive Chats connect you with our executive team through Q&As and discussions about their career journeys.You'll have opportunities to develop professional skills & learn more about career opportunities though business-specific learning sessions.You'll be assigned a mentor on day one. They'll be a great resource to get advice or direction on your project as well as your personal development and career path.Seattle employees enjoy commuter benefits, weekday catered lunches, and access to the Qualtrics Tower fitness center. Must be legally authorized to work in job location without Qualtrics sponsorship now or in the future The base pay range for this position is $68.5k - 85.5k per year; however, base pay offered may vary depending on location, job-related knowledge, education, skills, and experience. Relocation assistance may be included in an employment offer, in addition to a range of medical, financial, and other benefits, based on eligibility criteria. Qualtrics is an equal opportunity employer meaning that all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other protected characteristic. Applicants in the United States of America have rights under Federal Employment Laws: Family & Medical Leave Act, Equal Opportunity Employment, Employee Polygraph Protection Act Qualtrics is committed to the inclusion of all qualified individuals. As part of this commitment, Qualtrics will ensure that persons with disabilities are provided with reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please let your Qualtrics contact/recruiter know. Qualtrics Work Experience - As we look to the future, we believe that our teams are better together. Being together will help us learn more, grow faster and ultimately deliver better results for our customers and Qualtrics. Roles tied to an office location work 4 days per week in the office together and 1 day from home, with a strong spirit of flexibility around taking time for personal, health, and family moments in our work weeks. Our managers work with their teams to create a collaborative, engaged work environment, and arrangement that works for each of our team members. Not finding a role that’s the right fit for now? Qualtrics Insiders is the one-stop shop for all things Qualtrics Life. Sign up for exclusive access to content created with you in mind and get the scoop on what we have going on at Qualtrics - upcoming events, behind the behind the scenes stories from the team, interview tips, hot jobs, and more. No spam - we promise! You'll hear from us two times a month max with fresh, totally tailored info - so be sure to stay connected as you explore your best role and company fit.\\n\\n7th job description: Clarifai is a leading, full-lifecycle deep learning AI platform for computer vision, natural language processing, LLM's and audio recognition. We help organizations transform unstructured images, video, text, and audio data into structured data at a significantly faster and more accurate rate than humans would be able to do on their own. Founded in 2013 by Matt Zeiler, Ph.D. Clarifai has been a market leader in AI since winning the top five places in image classification at the 2013 ImageNet Challenge. Clarifai continues to grow with employees remotely based throughout the United States, Canada, Argentina, India and Estonia.  We have raised $100M in funding to date, with $60M coming from our most recent Series C, and are backed by industry leaders like Menlo Ventures, Union Square Ventures, Lux Capital, New Enterprise Associates, LDV Capital, Corazon Capital, Google Ventures, NVIDIA, Qualcomm and Osage. Your ImpactDevelop and execute product marketing strategies:Collaborate closely with cross-functional teams to rapidly iterate and refine product positioning and messaging for the developer and data science audience.Stay informed about market trends and swiftly adapt marketing strategies to capitalize on emerging opportunities.Create and deliver compelling product presentations, demos, and technical content that resonates with developers and data scientists.Product launch and go-to-market:Lead and execute the rapid go-to-market strategy for new product releases, collaborating closely with product management, engineering, and marketing teams to ensure successful launches.Define and implement innovative marketing campaigns targeted specifically at developers and data scientists, leveraging digital channels, social media, events and community platforms.Continuously monitor and analyze key metrics to measure the effectiveness of marketing campaigns, rapidly adapt strategies, and optimize for maximum impact.Customer advocacy and success:Act as a trusted advisor to customers, understanding their technical requirements, challenges, and success criteria.Gather customer feedback and insights to drive product enhancements and improvements.Collaborate with the customer success team to ensure successful product adoption and customer satisfaction.Empowerment and enablementManage and mentor a scrappy team of marketers, providing guidance, support, and feedback to help them excel in their roles.Develop comprehensive training materials and resources to educate internal teams, partners, and customers on product features, use cases, and best practices.Work closely with sales teams to equip them with the necessary technical knowledge and tools to effectively engage with developers and data scientists.Developer and data scientist community engagement:Build and nurture relationships with developer and data science communities through active participation in forums, conferences, meetups, and online platforms.Drive developer adoption and engagement by creating technical content, blog posts, tutorials, and sample code that demonstrates the value and utility of our products.Collaborate with influencers and industry experts to amplify product awareness within the target audience. Your OpportunityA proven leader in technical product marketing will find a unique opportunity to lead the product marketing efforts for Clarifai’s AI platform, captivating developers, data scientists and machine learning engineers with your developer marketing skills. As a pivotal member of our company, you will play a key role in accelerating our growth and establishing our brand within the AI communities.RequirementsBachelor's degree in Computer Science, Data Science, or a related technical field. A Master's degree is a plus. Extensive background in software development or data science, including hands-on experience with programming languages, development frameworks, and data analysis tools.Proven track record in technical product marketing, developer evangelism, or a related role within a fast-paced startup environment.In-depth understanding of the unique challenges and opportunities present in the developer and data science communities, and the ability to swiftly adapt marketing strategies to capture emerging trends.Excellent communication and presentation skills, with the ability to convey complex technical concepts in a concise and captivating manner.Strong agility and adaptability, with the ability to thrive in a rapidly evolving environment, and manage multiple projects simultaneously.Analytical mindset with a data-driven approach to measure marketing performance and drive informed decision-making.Passion for technology and an insatiable curiosity to stay ahead of the curve by keeping up-to-date with the latest industry trends, tools, and platforms.Production knowledge in machine learning and deep learning, at least at a conceptual level. Understanding of modern LLM's. Great to HaveComfort managing documentation using version control and peer review (e.g. via Github) Clarifai is proud to be an equal opportunity workplace dedicated to pursuing, hiring, and retaining a diverse workforce.\\n\\n8th job description: About KariusKarius is a venture-backed life science startup focused on transforming the way infectious diseases are diagnosed. Combining Next-Generation Sequencing and proprietary data analysis, we can identify over 1,000 pathogens from a single blood sample with typical turnaround time in one business day. By unlocking the information present in microbial cell-free DNA, we're helping doctors quickly solve their most challenging cases, with a future vision of accelerating clinical trials, discovering new microbes, and reducing patient suffering worldwide. Position SummaryWe are building and operating a unique software stack of cloud infrastructure, software services, APIs, web and mobile interactive interfaces, and AI-driven data analytics pipelines to deliver life-saving results in the highly complex infectious disease landscape. We believe the success of Karius’ products is driven by both our unique technology and the elegance of the software solution. We seek talented and passionate individuals who want to be part of this impactful journey of reaching the team’s ambitious goals, far beyond what any single individual could accomplish. As a Sr. Software Engineer in this space, your primary focus will be designing, developing and maintaining the backend and LIMS software and infrastructure to execute Karius Lab Diagnostics software in commercial and research setup. Why Should You Join Us?Karius core mission is to conquer infectious diseases through innovations around genomic sequencing and machine learning. The company’s platform is already delivering unprecedented insight into the microbial landscape, providing clinicians with a comprehensive test capable of identifying more than a thousand pathogens directly from blood. Through this journey, we realized that the microbial cell-free DNA platform may hold value that goes well beyond the direct diagnosis of infections. You, as part of the Karius team, will be able to see the immense opportunity to expand the human knowledge around this emerging topic and apply it directly to critical problems in human health and disease. Reports to: Sr. Director of Software Engineering Location: Redwood City, CA (Hybrid) or Remote (US) Primary Responsibilities • Design and development of backend software services that interact with the LIMS software and that drive the Karius genomics lab workflows and related business processes to generate life-saving diagnostic reports.• Follow Domain Driven Design to clearly document the service design and the interfaces.• Ensure the software services meet expected quality gates by developing unit and functional tests.• Collaborate with cross-functional teams such as Lab Operations, Customer Success, Product Management and Quality Engineering, and follow the defined Engineering SDLC to deliver value to the customers and users.• Contribute to the engineering organization’s technical efforts such as design and code review, technology evaluations and development of proof of concepts.• Provide production support of diagnostics software services.• Contribute to advancing a culture of a high-performing team by having close collaboration and engagement with the rest of the engineering team in solving challenges as they arise.  What’s Fun About the Job?Karius is operating at the edge of what is now known to be possible in infectious disease diagnostics. With that, comes a wave of new and incredible challenges and opportunities. To deliver on that value, you will be tapping into some of the most advanced technologies, architecting and innovating where the current solutions simply don't suffice. You will get to see how much your work really matters.  Travel: No travel required. Physical Requirements Subject to extended periods of sitting and/or standing, vision to monitor and moderate noise levels. Work is generally performed in an office environment.  Position RequirementsFirst and foremost, you are energized and motivated by the opportunity to build an elegant software. You enjoy seeing your creation work like a clock positively impacting thousands of people every year. You crave tough challenges in a super technical and collaborative environment that requires creativity and vision to navigate complex and ambiguous problems.  • BS or MS degree in Computer Science, Software Engineering or related technical fields involving algorithms and coding.• 5+ years of software engineering experience, including designing, developing and maintaining backend solutions in a production environment, including 2+ experience in LIMS software such as Illumina Clarity.• A deep understanding of various system architectural patterns, such as event driven microservices, and a strong hands on experience with related technologies such as Kafka.• Expert level experience with Typescript/javaScript stack using frameworks such as Express, Nest.js, Node.js.• Practical examples of complex system data modeling and servicing using REST, GraphQL, no-SQL/SQL databases & ORMs.• Experience with DevOps culture using cloud computing in AWS, Azure or GCP .• A deep understanding of and hands-on experience with the software deployment and operation using containerization technologies like Docker and container management like Kubernetes.• Experience with development lifecycle management tools like Jira, Confluence, gitAs a big plus, experience in healthcare, life sciences or other regulated industries. Personal Qualifications • Passionate, purpose-driven, and excited about Karius’ mission.• Mastered your craft yet eager to learn and grow.• Demonstrated ability to tackle complex problems.• Ability to work independently but also be an excellent team player.• Ability to work effectively and efficiently in a fast paced (startup) environment. At Karius, we value a diverse and inclusive workplace and provide equal employment opportunity for all applicants and employees and are committed to honor and invest in the full diversity of people, in our hiring, recruiting and development of employees across the Company. All qualified applicants for employment are encouraged to apply and will be considered without regard to an individual’s race, color, sex, gender identity and gender expression (including transgender individuals who are transitioning, have transitioned, or are perceived to be transitioning to the gender with which they identify), religion, age, national origin or ancestry, citizenship, physical or mental disability, medical condition, family care status, marital status, domestic partner status, sexual orientation, genetic information, military or veteran status, or any other basis protected by federal, state or local laws. If you are unable to submit your application due to a disability, please contact us at recruiting@kariusdx.com and we will accommodate qualified individuals with disabilities.\\n\\n9th job description: ⚡ Director, Machine Learning Infrastructure⚡🏥 $100M, Series D HealthTech 🏥🗺️ Remote, USA 🗺️💰 $300K+ 💰 Interested in the role? Please connect with the job poster for more details! A HealthTech company totally revolutionizing Data Science and Machine Learning related to Digital Therapeutics. Having closed a MASSIVE $100M Series D earlier this year, they are seeking a talented and experienced Machine Learning Platform Director to lead their cutting-edge machine learning initiatives and oversee the development and maintenance of their ML platform. Responsibilities:Lead and mentor a team of machine learning engineers, data scientists, and platform developers, whilst still being HANDS ON.Define and execute the machine learning platform roadmap aligned with business objectives.Oversee the design, implementation, and maintenance of the machine learning infrastructure using Docker and Kubernetes for containerization and orchestration.Implement and manage data pipelines and workflows using Airflow for efficient data processing and model deployment.Drive the utilization of Spark for distributed data processing and analytics.Collaborate with research teams to integrate and optimize models built with TensorFlow and PyTorch.Stay current with industry trends and emerging technologies in machine learning and AI.Collaborate with stakeholders to ensure successful implementation of machine learning projects.Monitor platform performance, troubleshoot issues, and optimize for scalability and reliability. Qualifications:Bachelor's or Master's degree in Computer Science, Engineering, or a related field.Proven experience (5+ years) in leading machine learning teams and projects.Strong expertise in Docker and Kubernetes for containerization and orchestration.Proficiency in building and managing data workflows using Apache Airflow.Experience with Spark for distributed data processing and analytics.Proficiency in developing and deploying machine learning models using TensorFlow and/or PyTorch.Excellent leadership, communication, and collaboration skills.Problem-solving mindset with the ability to drive results in a fast-paced environment.Experience in [specific industry/domain relevant to the company's focus - optional]. Why apply:Highly Competitive Base, 20% bonus + EquityRemote100% Covered Medical/ Dental/ Vision for you, 70% for dependentsLife InsuranceUnlimited PTO401K 🌎 The role is fully Remote 📧 Interested in applying? Please click on the ‘Easy Apply’ button or email me at Alexander.Hasselbach@Storm3.com ⚡ Storm3 is a HealthTech recruitment firm with clients across London, Europe and North America. To discuss open opportunities or career options, please visit our website www.storm3.com and follow the Storm3 Linked In page for the latest jobs and intel.\\n\\n10th job description: Data Scientist Data ScientistTitan Advanced Energy Solutions, Inc., Salem, MA  Titan Advanced Energy Solutions, headquartered in Salem, MA, develops revolutionary, ultrasound-based battery cell inspection systems. Using non-destructive, high-resolution, high-speed ultrasound technology, Titan’s IonSight analyzes cell morphology to detect critical manufacturing anomalies, directly addressing safety concerns and in-field risks. The novel in-line technology integrates into existing cell manufacturing processes to decrease the cost of quality, accurately classify cell quality grades, and evaluate lifetime performance and safety characteristics. Titan’s innovative strides have been recognized with numerous awards and funding from top clean energy programs and institutions, including Greentown Labs, the Massachusetts Clean Energy Center (MassCEC) and the Department of Energy. Growing and poised to continue this positive momentum, this is an exciting time to join the Titan team! Reporting to the Principal Data Scientist, you will work with our multi-disciplined, fast-paced team on a variety of interesting projects. We are looking for an independent thinker who is highly self-motivated, driven to achieve, goal and team-oriented, and passionate about clean technology. The ideal candidate will bring a passion for solving important problems with machine learning and deep learning approaches in ways that create data driven solutions leading to end products. Your bias to action combined with a learning mindset allows you to take calculated risks and unlock opportunities along the way. You will work with a diverse team on an array of cross-disciplinary projects centered around ultrasound time series signal data and composite image data; you will be responsible for holistic analysis, building machine learning models, feature development, and improvements to models in production. A successful candidate for this role will have a solid foundation of concepts in computer science and mathematics, experience analyzing and visualizing large and complex data sets, and experience building machine learning models to aid in analysis. Duties and Responsibilities:  · Self-driven analysis of ultrasound data from multiple battery types, looking for new ways to find anomalies, defects, or other notable features.· Use Machine Learning techniques to aid in analysis· Work with other engineering teams to develop new approaches to processing ultrasound data· Take models or analyses all the way from initial R&D to production· Follow engineering best practices across the data team, including code reviews, testing, reproducibility· Generate and maintain documentation as required· Other duties as assigned   Required skills: 2+ years industry experience in data science, machine learning, or similar positionsSelf-motivated and pro-active, with multi-tasking and critical thinking capabilitiesExpert proficiency with Python and related libraries Experience using Git or similar version control tools in a team environmentExperience with relational databases such as Snowflake· Good knowledge of cloud tools (AWS, GCP, Azure)Excellent understanding of algorithms, data structures, coding standards Preferred skills: BS and/or MS in Physics, Computer Science, Mathematics or similar technical fieldPractical experience with deep learning frameworks such as PyTorch and Tensorflow· Experience with Linux and shell scripting· Experience with Docker (docker-compose and swarm)· Previous working experience with ultrasound signal data or similar· Foundational knowledge of signal processing· Start-up experience a plus Personal Values: · Bias to action, self-motivated and entrepreneurial spirit· Attention to detail, effective time management, and pride in work· Dependable, trustworthy, empathetic & full of integrity· Strong collaborative communication skills; able to build consensus internally and externally Benefits:· Competitive Pay and Equity Incentive· Medical, Dental, Vision 80% covered – currently UHC HMO & PPO· Flex Spending – Health, Dependent Care, and Transit· 401(k) · PTO and Holidays· Long Term Disability 100% covered Learn more at www.titanaes.com Send your resume to careers@titanaes.com.  Titan welcomes applicants from every background – our diversity helps us thrive and serve our customers and each other. All employment decisions are based on qualifications, merit and business needs, without discrimination or bias. We are proud to be an equal opportunity employer. If you need assistance or accommodation due to a disability, please let us know.   \\n\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### make query\n",
    "similar_job_description = ''\n",
    "for i in range(len(response.json()['hits'])):\n",
    "    text = response.json()['hits'][i]['description']\n",
    "    clean_text = text.replace('\\n', ' ')\n",
    "    similar_job_description += f\"{i + 1}th job description: {clean_text}\\n\\n\"\n",
    "\n",
    "similar_job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44582"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(similar_job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"1th job description: X is Alphabet’s moonshot factory. We are a diverse group of inventors and entrepreneurs who build and launch technologies that aim to improve the lives of millions, even billions, of people. Our goal: 10x impact on the world’s most intractable problems, not just 10% improvement. We approach projects that have the aspiration and riskiness of research with the speed and ambition of a startup. About The Team Tidal is a team at X working on a moonshot to protect the ocean and preserve its ability to support life and help feed humanity, sustainably. Our initial area of focus is on developing hardware and software technologies that bring greater visibility and understanding of what’s happening under the water. Learn more about Project Tidal . About The Role Project Tidal is looking for a software engineer to design critical applications using machine learning and computer vision models for real world use cases, working closely with customers and partners to deploy solutions. This is an opportunity to work end to end with revolutionary hardware, real world customer applications, and cutting edge technologies. If you love to work on challenging and real world problems, please apply! How You Will Make 10X Impact Design and implement applications using machine learning and computer vision models to find solutions for real world problems.Develop hybrid enterprise applications with solid API support.Work closely with customers and partners to simplify solutions.Build insights to help customers visualize and analyze the trend to further optimize their business. What You Should Have Bachelor's degree in Computer Science, a related technical field involving software/systems engineering, or equivalent practical experience.4+ years of software development experience.Strong programming skills (preferred Golang, C++ or Python).Solid data analysis and troubleshooting skills.Experience in developing large scale cloud applications using APIs and developer platforms.Excellent communication skills. I'd Be Great If You Also Have These Experience working with IoT and/or sensors.Knowledge of ML models and pipelines.Experience working with large enterprise customers.\\n\\n2th job description: We are looking for a Principal Software Engineer with deep learning leadership experience to join our group! Come join NVIDIA's AI/AV Infrastructure team to develop state of the art MLOps infrastructure for our advanced autonomous driving platform. Together, we will help advance NVIDIA's capacity to build and deploy leading solutions for a broad range of AI-based applications.  To ensure that our fleet of autonomous vehicles scalably record, analyze, and train our state-of-the-art machine learning models, we need to stay a step ahead of our engineering partners. We need someone who has built systems that handle petabyte-scale datasets, or is able to map their prior experience to develop systems that handle such scale. We are either directly involved or in collaboration with our partner teams in all the data lifecycle activities. To ensure we deliver on the expectations of our customers, our solutions must be scalable and performant. Our approach must embrace engineering and operational excellence practices across the stack. We need someone who can ensure that the primitives which make our platform build, scale, and ship reliably. You will embed in one of our engineering teams that has high visibility and work on both product-focused and infrastructure roles.  What You'll Be Doing  Contributing to the development of Deep Learning software infrastructure for large scale image and video processing tasks and leading major technical projects for the team. The range of applications you'll work on includes automotive driver assistance, autonomous navigation, and robotics.Be a part of a dynamic product and customer-oriented team. Your expertise, creativity and leadership will help bring the future of self-driving cars to our doorsteps.Be responsible for data modeling, schema design, dataset curation, search, and discovery  What We Need To See  10+ years of relevant work experience in high performance/distributed computing, including technical leadership experience.3+ years of relevant experience in productizing deep learning systems.You have a BS or MS in Computer Science, Electrical Engineering, or equivalent experience.Experience with MLOps platforms such as Flyte, MLFlow, or similar.Experience with any of the deep learning frameworks: PyTorch, Tensorflow, Keras, or similar.Proven track record to architect and develop data-first, production machine learning pipelines that scale out to very large datasets.Track record of elevating teams and increasing their velocity by helping others.Experience mentoring junior developers.Good understanding of highly parallel compute, storage, and software architectures.Experience working with multi-node/distributed training, data loading and image/video processing.Excellent communication and organization skills.Self-motivation, outstanding collaboration with peers and users, customer focused mindset.  Ways To Stand Out Of The Crowd  Previous experience of scaling up and optimizing HPC, computer vision or deep learning training pipelines to terabyte scale datasets is a huge plus.Experience with Go Lang, C++ and CUDA.Contributions to open-source DNN frameworks.Prior experience using machine learning or neural networks to tackle problems in image or video analysis.  NVIDIA is widely considered to be one of the technology world’s most desirable employers. We have some of the most forward-thinking and hardworking people on the planet working for us. If you're creative, passionate and self-motivated, we want to hear from you! NVIDIA is leading the way in groundbreaking developments in Artificial Intelligence, High-Performance Computing and Visualization. The GPU, our invention, serves as the visual cortex of modern computers and is at the heart of our products and services.  The base salary range is 268,000 USD - 414,000 USD. Your base salary will be determined based on your location, experience, and the pay of employees in similar positions.  You will also be eligible for equity and benefits .  NVIDIA accepts applications on an ongoing basis.   NVIDIA is committed to fostering a diverse work environment and proud to be an equal opportunity employer. As we highly value diversity in our current and future employees, we do not discriminate (including in our hiring and promotion practices) on the basis of race, religion, color, national origin, gender, gender expression, sexual orientation, age, marital status, veteran status, disability status or any other characteristic protected by law.  \\n\\n3th job description: JOB TITLE: Big Data ArchitectLOCATION: Auburn Hills, MIJOB DESCRIPTION: Pay rate: $74.60 Location: Auburn Hills, MI OR Herndon, VAWorker Type: Fixed MonthlyEnhanced PTO/Holidays SRe-Classified to HybridMust be local to Auburn Hills, MI or Herndon, VA Important Requirements• 3+ years of hands-on implementation experience working with a combination of the following technologies: JavaScript, React, Data Java Based Solutions (API / Batch), Java REST APIs.• Experience building web services (SOAP/Rest) using Java APIs and tools, such as JAX-RPC• Experience with the Spring Framework and general MVC• 5+ years’ programming/scripting languages Java  The Big Data Developer will be responsible for the design and build of world class high-volume real-time data ingestion and processing frameworks and advanced analytics on big data platforms. He/She will research, develop, optimize, and innovate frameworks and patterns for enterprise scale data analysis and computations as part of our Big Data, Connected Car and Internet of Things initiatives. • Work as an integrated member of the technology team and drive cross functional international Big Data initiatives from beginning to end: build relationships with partner teams and stakeholders in Germany and the US, distill and present key insights in support of decision making • Design and Build world class high-volume real-time data ingestion and processing frameworks and advanced analytics on big data platforms. • Research, develop, optimize, and innovate frameworks and patterns for enterprise scale data analysis and computations as part of our Big Data, Connected Car and Internet of Things initiatives. • Lead the implementation of Hadoop platform strategy development by creating architectureblueprints, validating designs and providing recommendations on the enterprise platform strategic roadmap • Present technology solutions to senior leadership in Germany and the US in verbal, visual, and written media and influence architecture decisions that will lead the transformation of our Connected Car analytics platform and IT overall. • 3+ years of hands-on implementation experience working with a combination of the following technologies: JavaScript, React, Data Java Based Solutions (API / Batch), Java REST APIs. • 3+ years experience in designing and implementing big data solutions. This includes creating the requirements analysis, design of the technical architecture, design of the application design and development, testing, and deployment of the proposed solution • Research the tool market, follow new research streams and build partnerships with start-ups, universities and local communities • Experience building web services (SOAP/Rest) using Java APIs and tools, such as JAX-RPC • Experience with the Spring Framework and general MVC frameworks Education Requirements: A Bachelors degree in Computer science engineering or related field Qualifications• 5+ years programming/scripting languages Java• 2+ years of experience of developing solutions in cloud environments (Azure, AWS etc) with focus on analytics stack.• 2+ years of experience in big data streaming frameworks, data processing and real-time ingestion patterns.• Experience working with and evaluating open source technologies and demonstrated ability to make objective choices• Experience architecting highly scalable, highly concurrent and low latency systems• Experience scaling applications to processing multiple petabytes• Knowledge of software/data design methods, data structures, and modeling standards Nice to have: Knowledge of Chef scripting, Docker containers• Working Experience with continuous integration and continuous delivery tools• Experience with multiple cloud computing platforms• Experience with more than one data streaming technologies• Ability to communicate complex architectures and insights in a clear, precise, and actionable manner Benefit offerings include medical, dental, vision, term life insurance, short-term disability insurance, additional voluntary benefits, commuter benefits and 401K plan. Our program provides employees the flexibility to choose the type of coverage that meets their individual needs. Available paid leave may include Paid Sick Leave, where required by law; any other paid leave required by Federal, State or local law; and Holiday pay upon meeting eligibility criteria.Disclaimer: These benefit offerings do not apply to client-recruited jobs and jobs which are direct hire to a client Equal Opportunity Employer/Veterans/DisabledNot available on a C2C or C2H basisTo read our Candidate Privacy Information Statement, which explains how we will use your information, please visit https://www.modis.com/en-us/candidate-privacy/ The Company will consider qualified applicants with arrest and conviction records.\\n\\n4th job description: Calling all AWS-focused Data Engineers! Do you have skills in Redshift and Glue? Or a BI background in Quicksight? We are hiring for multiple positions to make an impact with an Amazon Premier Partner and their clients. Engineers do not need to have all qualifications to apply, Redshift and Glue or Quicksight are experience required.  QualificationsAWS Certified Big Data – SpecialtyExperience with Amazon QuickSight, Amazon API Gateway, and RedshiftStrong proficiency in programming languages such as Python, Java, or Scala, with expertise in data processing frameworks and libraries (e.g., Spark, Hadoop, SQL, etc.)In-depth knowledge of database systems (relational and NoSQL), data modeling, and data warehousing conceptsProficiency in designing and implementing ETL processes and data integration workflows using tools like Apache Airflow, Informatica, or TalendFamiliarity with data governance practices, data quality frameworks, and data security principlesAdvanced knowledge and technical proficiency with ETL, cloud-based data warehousing, and Apache Spark.Strong knowledge of AWS-specific services, including Lake Formation, Amazon Aurora, Amazon Data Pipeline, Amazon Athena, Glue, Amazon S3, Amazon DynamoDB, Amazon Relational Database Service (RDS), Amazon Elastic Map Reduce (EMR), Amazon Kinesis, Database Migration Services, etc.Familiarity and understanding of Common Data Engineering tools like: Apache Spark, Apache Airflow, Apache Lite, Apache Kafka, dbt, great_expectations·Bachelor's or master's degree in computer science, Engineering or a related field\\n\\n5th job description: X is Alphabet’s moonshot factory. We are a diverse group of inventors and entrepreneurs who build and launch technologies that aim to improve the lives of millions, even billions, of people. Our goal: 10x impact on the world’s most intractable problems, not just 10% improvement. We approach projects that have the aspiration and riskiness of research with the speed and ambition of a startup. About The Team Tidal is a team at X working on a moonshot to protect the ocean and preserve its ability to support life and help feed humanity, sustainably. Our initial area of focus is on developing hardware and software technologies that bring greater visibility and understanding of what’s happening under the water. Learn more about Project Tidal . About The Role As an Applied Machine Learning Software Engineer at Tidal, you will be working alongside other software engineers, perception experts, and research scientists to develop and deploy state-of-the-art methods to create a platform leveraging perception and machine learning to solve humanity’s biggest problems — from food production to renewable energy to climate change — by sustainably utilizing the ocean. Your role will be to enable developers to run ML workflows smoothly and efficiently. You will develop sustainable, scalable solutions to ensure the reliability and performance of these ML workflows, improve engineer productivity and ultimately help advance our Perception and ML Platform. If you love getting tech to work on challenging, real world problems, please apply! How You Will Make 10X Impact Work with our customers to understand the problem space, run experiments, collect data, and design novel and breakthrough ML solutions Profile ML performance at both model level and system level, identify performance bottlenecks and optimization opportunitiesImprove and streamline large-scale machine learning workflows for training and inference by analyzing, understanding, and fixing bottlenecksEnable better component-wise testing of training workflowsAutomate data upload/processing/training/evaluating/deploying/optimizing pipelines and develop monitoring and notification tooling to track statistics of the pipelines, improving debuggability and introspection into these complex workflowsRespond to and resolve emergent problems in production; test ML training pipelines; write software and build automation to prevent problem recurrenceKeep track of major changes and trends in infrastructure and enable adoption of new frameworks and systems without significant impact on development workEngage in capacity planning, quota management, and demand forecasting for ML workflowsCollaborate with stakeholder teams to implement and evolve large-scale Machine Learning infrastructure What You Should Have BS degree in Computer Science or a related field, or equivalent practical experienceStrong programming skills in Python and/or C++Expertise in data structures, algorithms and complexity analysis.Experience designing, analyzing, and troubleshooting large-scale distributed systems, especially enterprise cloud services (e.g., GCP, AWS)Experience with ML platforms, solutions, and infrastructure deployed to solve real world problems It’d Be Great If You Also Had These Experience with C++ and/or GoExperience with TensorFlow or PytorchExperience with SQL or similar, and parallel data processing pipelines (e.g. Flume, Apache Beam)Expertise in architecting and deploying machine learning pipelines at scaleExpertise in getting ML models into productionFamiliarity with state-of-the-art ML models for perception/computer vision tasksCustomer-facing experience creating software solutionsMS or PhD degree in Computer Science or a related field, or equivalent practical experience\\n\\n6th job description: The Qualtrics XM Platform™ is a system of action that helps businesses to attract customers who stay longer and buy more, to engage and empower employees to do the best work of their lives, to develop breakthrough products people love, and to build a brand people can’t imagine living without. Joining Qualtrics means becoming part of a team bold enough to chase breakthrough experiences - like building a technology that will be a force for good. A team committed to diversity, equity, and inclusion because of a conviction that every voice holds value, with a vision for representation that matches the world around us and inclusion that far exceeds it. You could belong to a team whose values center on transparency, being all in, having customer obsession, acting as one team, and operating with scrappiness. All so you can do the best work of your career. We believe every interaction is an opportunity. Are we yours? At Qualtrics, we create software the world’s best brands use to deliver exceptional frontline experiences, build high-performing teams, and design products people love. But we are more than a platform—we are the creators and stewards of the Experience Management category serving over 18K clients globally. Building a category takes grit, determination, and a disdain for convention—but most of all it requires close-knit, high-functioning teams with an unwavering dedication to serving our customers. When you join one of our teams, you’ll be part of a nimble group that’s empowered to set aggressive goals and move fast to achieve them. Strategic risks are encouraged and complex problems are solved together, by passing the mic and iterating until the best solution comes to light. You won’t have to look to find growth opportunities—ready or not, they’ll find you. From retail to government to healthcare, we’re on a mission to bring humanity, connection, and empathy back to business. Join over 6,000 people across the globe who think that’s work worth doing. Software Engineer - Intern Why We Have This Role As a software engineer at Qualtrics, you will be building systems to help our customers both understand and respond to the experience data provided by their customers or employees. Designing systems in an agile environment to withstand hyper growth and owning quality from end to end is a rewarding challenge and one of the reasons Qualtrics is such an exciting place to work! How You’ll Find Success Strong level of curiosityAbility to create trust in customers and teams through thorough communicationTakes initiative and shows scrappiness in getting things doneProven ability to work well in teams - partnering with managers, cross functional teams, and teammatesTakes analytical mindset to approach problems and find solutionsShows desire to learn new skills and grow in the role How You’ll Grow Develop the ability to build scalable, fast, robust, and simple SaaS solutions.Develop familiarity with containerization and full-stack development.Learn to implement new functionality from provided requirements and specifications.Benefit from working with other engineers, tech-ops, and product managersLearn Agile methodologies by attending daily stand-up meetings, prioritizing tasks, and working with a sense of urgency to meet a scheduled plan to deliver value to our customers Things You’ll Do You'll own a project. It will push you out of your comfort zone, and you'll see meaningful growth as a result.Design distributed, low latency services for ingesting, processing, and aggregating dataBuild integrations with SaaS leaders like Slack, Salesforce, and TableauCreate analytics that identify trends and sentiment in free-form text data using natural language processing and machine learningBuild widgets for visualizing data in dashboards and reportsDevelop an integrated ticketing platform that allows organizations to close the loop on customer feedbackBuild world-class survey editing and survey taking experiences What We’re Looking For On Your Resume Currently studying for a degree in Computer Science, Software Engineering, or Computer EngineeringExperience with Web-related technologies including HTML/CSS and JavaScriptExperience with JavaScript frameworks including angular or nodeExperience with modern programming languages (Java, PHP, Scala)Database / Data Storage experience (SQL / MySQL)Strong level of curiosityMust be legally authorized to work in job location without Qualtrics sponsorship now or in the futureAvailable for a 12 week internship during summer of 2024 What You Should Know About This Team Our team is a collection of extremely passionate engineers who are riding the cutting edge of cloud computing and web scalability. We organize and sort terabytes of data and develop solutions that are used by millions of users every day. We design tools that make sophisticated research simple. Few teams offer such amazing learning opportunities and possibilities for advancement like the Qualtrics Engineering team. Our Team’s Favorite Perks and Benefits Relocation and financial support for housing.We like to retain our high performers. In fact, 85% of our interns receive an offer to return full time after graduation.ExeQtive Chats connect you with our executive team through Q&As and discussions about their career journeys.You'll have opportunities to develop professional skills & learn more about career opportunities though business-specific learning sessions.You'll be assigned a mentor on day one. They'll be a great resource to get advice or direction on your project as well as your personal development and career path.Seattle employees enjoy commuter benefits, weekday catered lunches, and access to the Qualtrics Tower fitness center. Must be legally authorized to work in job location without Qualtrics sponsorship now or in the future The base pay range for this position is $68.5k - 85.5k per year; however, base pay offered may vary depending on location, job-related knowledge, education, skills, and experience. Relocation assistance may be included in an employment offer, in addition to a range of medical, financial, and other benefits, based on eligibility criteria. Qualtrics is an equal opportunity employer meaning that all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, disability, status as a protected veteran, or any other protected characteristic. Applicants in the United States of America have rights under Federal Employment Laws: Family & Medical Leave Act, Equal Opportunity Employment, Employee Polygraph Protection Act Qualtrics is committed to the inclusion of all qualified individuals. As part of this commitment, Qualtrics will ensure that persons with disabilities are provided with reasonable accommodations. If reasonable accommodation is needed to participate in the job application or interview process, to perform essential job functions, and/or to receive other benefits and privileges of employment, please let your Qualtrics contact/recruiter know. Qualtrics Work Experience - As we look to the future, we believe that our teams are better together. Being together will help us learn more, grow faster and ultimately deliver better results for our customers and Qualtrics. Roles tied to an office location work 4 days per week in the office together and 1 day from home, with a strong spirit of flexibility around taking time for personal, health, and family moments in our work weeks. Our managers work with their teams to create a collaborative, engaged work environment, and arrangement that works for each of our team members. Not finding a role that’s the right fit for now? Qualtrics Insiders is the one-stop shop for all things Qualtrics Life. Sign up for exclusive access to content created with you in mind and get the scoop on what we have going on at Qualtrics - upcoming events, behind the behind the scenes stories from the team, interview tips, hot jobs, and more. No spam - we promise! You'll hear from us two times a month max with fresh, totally tailored info - so be sure to stay connected as you explore your best role and company fit.\\n\\n7th job description: Clarifai is a leading, full-lifecycle deep learning AI platform for computer vision, natural language processing, LLM's and audio recognition. We help organizations transform unstructured images, video, text, and audio data into structured data at a significantly faster and more accurate rate than humans would be able to do on their own. Founded in 2013 by Matt Zeiler, Ph.D. Clarifai has been a market leader in AI since winning the top five places in image classification at the 2013 ImageNet Challenge. Clarifai continues to grow with employees remotely based throughout the United States, Canada, Argentina, India and Estonia.  We have raised $100M in funding to date, with $60M coming from our most recent Series C, and are backed by industry leaders like Menlo Ventures, Union Square Ventures, Lux Capital, New Enterprise Associates, LDV Capital, Corazon Capital, Google Ventures, NVIDIA, Qualcomm and Osage. Your ImpactDevelop and execute product marketing strategies:Collaborate closely with cross-functional teams to rapidly iterate and refine product positioning and messaging for the developer and data science audience.Stay informed about market trends and swiftly adapt marketing strategies to capitalize on emerging opportunities.Create and deliver compelling product presentations, demos, and technical content that resonates with developers and data scientists.Product launch and go-to-market:Lead and execute the rapid go-to-market strategy for new product releases, collaborating closely with product management, engineering, and marketing teams to ensure successful launches.Define and implement innovative marketing campaigns targeted specifically at developers and data scientists, leveraging digital channels, social media, events and community platforms.Continuously monitor and analyze key metrics to measure the effectiveness of marketing campaigns, rapidly adapt strategies, and optimize for maximum impact.Customer advocacy and success:Act as a trusted advisor to customers, understanding their technical requirements, challenges, and success criteria.Gather customer feedback and insights to drive product enhancements and improvements.Collaborate with the customer success team to ensure successful product adoption and customer satisfaction.Empowerment and enablementManage and mentor a scrappy team of marketers, providing guidance, support, and feedback to help them excel in their roles.Develop comprehensive training materials and resources to educate internal teams, partners, and customers on product features, use cases, and best practices.Work closely with sales teams to equip them with the necessary technical knowledge and tools to effectively engage with developers and data scientists.Developer and data scientist community engagement:Build and nurture relationships with developer and data science communities through active participation in forums, conferences, meetups, and online platforms.Drive developer adoption and engagement by creating technical content, blog posts, tutorials, and sample code that demonstrates the value and utility of our products.Collaborate with influencers and industry experts to amplify product awareness within the target audience. Your OpportunityA proven leader in technical product marketing will find a unique opportunity to lead the product marketing efforts for Clarifai’s AI platform, captivating developers, data scientists and machine learning engineers with your developer marketing skills. As a pivotal member of our company, you will play a key role in accelerating our growth and establishing our brand within the AI communities.RequirementsBachelor's degree in Computer Science, Data Science, or a related technical field. A Master's degree is a plus. Extensive background in software development or data science, including hands-on experience with programming languages, development frameworks, and data analysis tools.Proven track record in technical product marketing, developer evangelism, or a related role within a fast-paced startup environment.In-depth understanding of the unique challenges and opportunities present in the developer and data science communities, and the ability to swiftly adapt marketing strategies to capture emerging trends.Excellent communication and presentation skills, with the ability to convey complex technical concepts in a concise and captivating manner.Strong agility and adaptability, with the ability to thrive in a rapidly evolving environment, and manage multiple projects simultaneously.Analytical mindset with a data-driven approach to measure marketing performance and drive informed decision-making.Passion for technology and an insatiable curiosity to stay ahead of the curve by keeping up-to-date with the latest industry trends, tools, and platforms.Production knowledge in machine learning and deep learning, at least at a conceptual level. Understanding of modern LLM's. Great to HaveComfort managing documentation using version control and peer review (e.g. via Github) Clarifai is proud to be an equal opportunity workplace dedicated to pursuing, hiring, and retaining a diverse workforce.\\n\\n8th job description: About KariusKarius is a venture-backed life science startup focused on transforming the way infectious diseases are diagnosed. Combining Next-Generation Sequencing and proprietary data analysis, we can identify over 1,000 pathogens from a single blood sample with typical turnaround time in one business day. By unlocking the information present in microbial cell-free DNA, we're helping doctors quickly solve their most challenging cases, with a future vision of accelerating clinical trials, discovering new microbes, and reducing patient suffering worldwide. Position SummaryWe are building and operating a unique software stack of cloud infrastructure, software services, APIs, web and mobile interactive interfaces, and AI-driven data analytics pipelines to deliver life-saving results in the highly complex infectious disease landscape. We believe the success of Karius’ products is driven by both our unique technology and the elegance of the software solution. We seek talented and passionate individuals who want to be part of this impactful journey of reaching the team’s ambitious goals, far beyond what any single individual could accomplish. As a Sr. Software Engineer in this space, your primary focus will be designing, developing and maintaining the backend and LIMS software and infrastructure to execute Karius Lab Diagnostics software in commercial and research setup. Why Should You Join Us?Karius core mission is to conquer infectious diseases through innovations around genomic sequencing and machine learning. The company’s platform is already delivering unprecedented insight into the microbial landscape, providing clinicians with a comprehensive test capable of identifying more than a thousand pathogens directly from blood. Through this journey, we realized that the microbial cell-free DNA platform may hold value that goes well beyond the direct diagnosis of infections. You, as part of the Karius team, will be able to see the immense opportunity to expand the human knowledge around this emerging topic and apply it directly to critical problems in human health and disease. Reports to: Sr. Director of Software Engineering Location: Redwood City, CA (Hybrid) or Remote (US) Primary Responsibilities • Design and development of backend software services that interact with the LIMS software and that drive the Karius genomics lab workflows and related business processes to generate life-saving diagnostic reports.• Follow Domain Driven Design to clearly document the service design and the interfaces.• Ensure the software services meet expected quality gates by developing unit and functional tests.• Collaborate with cross-functional teams such as Lab Operations, Customer Success, Product Management and Quality Engineering, and follow the defined Engineering SDLC to deliver value to the customers and users.• Contribute to the engineering organization’s technical efforts such as design and code review, technology evaluations and development of proof of concepts.• Provide production support of diagnostics software services.• Contribute to advancing a culture of a high-performing team by having close collaboration and engagement with the rest of the engineering team in solving challenges as they arise.  What’s Fun About the Job?Karius is operating at the edge of what is now known to be possible in infectious disease diagnostics. With that, comes a wave of new and incredible challenges and opportunities. To deliver on that value, you will be tapping into some of the most advanced technologies, architecting and innovating where the current solutions simply don't suffice. You will get to see how much your work really matters.  Travel: No travel required. Physical Requirements Subject to extended periods of sitting and/or standing, vision to monitor and moderate noise levels. Work is generally performed in an office environment.  Position RequirementsFirst and foremost, you are energized and motivated by the opportunity to build an elegant software. You enjoy seeing your creation work like a clock positively impacting thousands of people every year. You crave tough challenges in a super technical and collaborative environment that requires creativity and vision to navigate complex and ambiguous problems.  • BS or MS degree in Computer Science, Software Engineering or related technical fields involving algorithms and coding.• 5+ years of software engineering experience, including designing, developing and maintaining backend solutions in a production environment, including 2+ experience in LIMS software such as Illumina Clarity.• A deep understanding of various system architectural patterns, such as event driven microservices, and a strong hands on experience with related technologies such as Kafka.• Expert level experience with Typescript/javaScript stack using frameworks such as Express, Nest.js, Node.js.• Practical examples of complex system data modeling and servicing using REST, GraphQL, no-SQL/SQL databases & ORMs.• Experience with DevOps culture using cloud computing in AWS, Azure or GCP .• A deep understanding of and hands-on experience with the software deployment and operation using containerization technologies like Docker and container management like Kubernetes.• Experience with development lifecycle management tools like Jira, Confluence, gitAs a big plus, experience in healthcare, life sciences or other regulated industries. Personal Qualifications • Passionate, purpose-driven, and excited about Karius’ mission.• Mastered your craft yet eager to learn and grow.• Demonstrated ability to tackle complex problems.• Ability to work independently but also be an excellent team player.• Ability to work effectively and efficiently in a fast paced (startup) environment. At Karius, we value a diverse and inclusive workplace and provide equal employment opportunity for all applicants and employees and are committed to honor and invest in the full diversity of people, in our hiring, recruiting and development of employees across the Company. All qualified applicants for employment are encouraged to apply and will be considered without regard to an individual’s race, color, sex, gender identity and gender expression (including transgender individuals who are transitioning, have transitioned, or are perceived to be transitioning to the gender with which they identify), religion, age, national origin or ancestry, citizenship, physical or mental disability, medical condition, family care status, marital status, domestic partner status, sexual orientation, genetic information, military or veteran status, or any other basis protected by federal, state or local laws. If you are unable to submit your application due to a disability, please contact us at recruiting@kariusdx.com and we will accommodate qualified individuals with disabilities.\\n\\n9th job description: ⚡ Director, Machine Learning Infrastructure⚡🏥 $100M, Series D HealthTech 🏥🗺️ Remote, USA 🗺️💰 $300K+ 💰 Interested in the role? Please connect with the job poster for more details! A HealthTech company totally revolutionizing Data Science and Machine Learning related to Digital Therapeutics. Having closed a MASSIVE $100M Series D earlier this year, they are seeking a talented and experienced Machine Learning Platform Director to lead their cutting-edge machine learning initiatives and oversee the development and maintenance of their ML platform. Responsibilities:Lead and mentor a team of machine learning engineers, data scientists, and platform developers, whilst still being HANDS ON.Define and execute the machine learning platform roadmap aligned with business objectives.Oversee the design, implementation, and maintenance of the machine learning infrastructure using Docker and Kubernetes for containerization and orchestration.Implement and manage data pipelines and workflows using Airflow for efficient data processing and model deployment.Drive the utilization of Spark for distributed data processing and analytics.Collaborate with research teams to integrate and optimize models built with TensorFlow and PyTorch.Stay current with industry trends and emerging technologies in machine learning and AI.Collaborate with stakeholders to ensure successful implementation of machine learning projects.Monitor platform performance, troubleshoot issues, and optimize for scalability and reliability. Qualifications:Bachelor's or Master's degree in Computer Science, Engineering, or a related field.Proven experience (5+ years) in leading machine learning teams and projects.Strong expertise in Docker and Kubernetes for containerization and orchestration.Proficiency in building and managing data workflows using Apache Airflow.Experience with Spark for distributed data processing and analytics.Proficiency in developing and deploying machine learning models using TensorFlow and/or PyTorch.Excellent leadership, communication, and collaboration skills.Problem-solving mindset with the ability to drive results in a fast-paced environment.Experience in [specific industry/domain relevant to the company's focus - optional]. Why apply:Highly Competitive Base, 20% bonus + EquityRemote100% Covered Medical/ Dental/ Vision for you, 70% for dependentsLife InsuranceUnlimited PTO401K 🌎 The role is fully Remote 📧 Interested in applying? Please click on the ‘Easy Apply’ button or email me at Alexander.Hasselbach@Storm3.com ⚡ Storm3 is a HealthTech recruitment firm with clients across London, Europe and North America. To discuss open opportunities or career options, please visit our website www.storm3.com and follow the Storm3 Linked In page for the latest jobs and intel.\\n\\n10th job description: Data Scientist Data ScientistTitan Advanced Energy Solutions, Inc., Salem, MA  Titan Advanced Energy Solutions, headquartered in Salem, MA, develops revolutionary, ultrasound-based battery cell inspection systems. Using non-destructive, high-resolution, high-speed ultrasound technology, Titan’s IonSight analyzes cell morphology to detect critical manufacturing anomalies, directly addressing safety concerns and in-field risks. The novel in-line technology integrates into existing cell manufacturing processes to decrease the cost of quality, accurately classify cell quality grades, and evaluate lifetime performance and safety characteristics. Titan’s innovative strides have been recognized with numerous awards and funding from top clean energy programs and institutions, including Greentown Labs, the Massachusetts Clean Energy Center (MassCEC) and the Department of Energy. Growing and poised to continue this positive momentum, this is an exciting time to join the Titan team! Reporting to the Principal Data Scientist, you will work with our multi-disciplined, fast-paced team on a variety of interesting projects. We are looking for an independent thinker who is highly self-motivated, driven to achieve, goal and team-oriented, and passionate about clean technology. The ideal candidate will bring a passion for solving important problems with machine learning and deep learning approaches in ways that create data driven solutions leading to end products. Your bias to action combined with a learning mindset allows you to take calculated risks and unlock opportunities along the way. You will work with a diverse team on an array of cross-disciplinary projects centered around ultrasound time series signal data and composite image data; you will be responsible for holistic analysis, building machine learning models, feature development, and improvements to models in production. A successful candidate for this role will have a solid foundation of concepts in computer science and mathematics, experience analyzing and visualizing large and complex data sets, and experience building machine learning models to aid in analysis. Duties and Responsibilities:  · Self-driven analysis of ultrasound data from multiple battery types, looking for new ways to find anomalies, defects, or other notable features.· Use Machine Learning techniques to aid in analysis· Work with other engineering teams to develop new approaches to processing ultrasound data· Take models or analyses all the way from initial R&D to production· Follow engineering best practices across the data team, including code reviews, testing, reproducibility· Generate and maintain documentation as required· Other duties as assigned   Required skills: 2+ years industry experience in data science, machine learning, or similar positionsSelf-motivated and pro-active, with multi-tasking and critical thinking capabilitiesExpert proficiency with Python and related libraries Experience using Git or similar version control tools in a team environmentExperience with relational databases such as Snowflake· Good knowledge of cloud tools (AWS, GCP, Azure)Excellent understanding of algorithms, data structures, coding standards Preferred skills: BS and/or MS in Physics, Computer Science, Mathematics or similar technical fieldPractical experience with deep learning frameworks such as PyTorch and Tensorflow· Experience with Linux and shell scripting· Experience with Docker (docker-compose and swarm)· Previous working experience with ultrasound signal data or similar· Foundational knowledge of signal processing· Start-up experience a plus Personal Values: · Bias to action, self-motivated and entrepreneurial spirit· Attention to detail, effective time management, and pride in work· Dependable, trustworthy, empathetic & full of integrity· Strong collaborative communication skills; able to build consensus internally and externally Benefits:· Competitive Pay and Equity Incentive· Medical, Dental, Vision 80% covered – currently UHC HMO & PPO· Flex Spending – Health, Dependent Care, and Transit· 401(k) · PTO and Holidays· Long Term Disability 100% covered Learn more at www.titanaes.com Send your resume to careers@titanaes.com.  Titan welcomes applicants from every background – our diversity helps us thrive and serve our customers and each other. All employment decisions are based on qualifications, merit and business needs, without discrimination or bias. We are proud to be an equal opportunity employer. If you need assistance or accommodation due to a disability, please let us know.   \\n\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_job_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://192.168.31.45:8888/compare'\n",
    "dummy_query = {\n",
    "    \"query\": {\n",
    "        \"user-info\": \n",
    "        '''\n",
    "        Software engineer with expertise in deep learning and cloud technologies. Graduate from the University of Melbourne with a master’s degree in IT and an outstanding academic records. Skilled in research and development in the cutting-edge AI models, especially in computer vision. Experienced in implementing AI solutions from major providers into existing software. Recognized for keen problem-solving skills and can-do attitude.\n",
    "\n",
    "        Vision HQ                                                                                                                                    Brisbane, QLD\n",
    "        SOFTWARE ENGINEER INTERN                                                                              Dec 2022 – Dec 2023\n",
    "        Developed and CI/CD deep learning models to solve specific business tasks.\n",
    "        Processed in-house data and construct optimized data pipelines to feed ML models.\n",
    "        Collaborated with software engineers on production systems and applications.\n",
    "\n",
    "        Generative AI job analyzing and matching system                               Feb 2024 – May 2024\n",
    "        #Large Language Model #Natural Language Processing\n",
    "        Leading the prototyping of a Gen-AI tool designed to provide job seekers with insights of demanding qualifications on individual resume.\n",
    "        Integrating GPT API and retrieval-augmented generation to use most up-to-date data.\n",
    "\n",
    "        Targeted billboard advertising system                                                    Jan 2024 – Mar 2024\n",
    "        #Machine Learning #Computer Vision\n",
    "        Developed an XGBoost ML model to predict ad effectiveness using real-time demographic data from digital billboard footage.\n",
    "        Retrieved attributes from video footage data into tabular data for enhanced analytics and model training.\n",
    "        Integrated computer vision (Azure Cognition) techniques to analyze crowd compositions.\n",
    "\n",
    "        Computer vision road monitoring system \t\t                         Jan 2023 – Dec 2023\n",
    "        #Computer Vision #Cloud Computing\n",
    "        Finetuned open-source computer vision models using in-house dataset, to provide tailored solution of road safety applications for smarter road management solutions.\n",
    "        Orchestrated the design, development, and testing of workflows optimized for cloud.\n",
    "        Implemented a seamless model pipeline on Google Cloud Platform, encompassing the entire spectrum from data ingestion to delivering actionable insights.\n",
    "\n",
    "        Research project for national bushfire satellite images                       Aug 2023 – Nov 2023\n",
    "        #Image Segmentation #Pattern Recognition\n",
    "        Led the evaluation of advanced CV models on satellite bushfire imagery analysis, to aid bushfire emergency planning in semi-real time.\n",
    "        Modified a ViT model to process multi-spectral imagery, resulting in 88% F1-score.\n",
    "        Research paper in-depth insights well received, under review for publication.\n",
    "\n",
    "        Full-stack web app for residents' sentiment analysis.                           Feb 2023 – Jun 2024\n",
    "        #Distributed and Parallel System #Natural Language Processing\n",
    "        Led the web app development to facilitate the analysis of residents’ satisfaction.\n",
    "        Construed frontend and backend services using React and Flask.\n",
    "        Automated deployment and scaling by utilizing Docker Swarm and Ansible.\n",
    "\n",
    "        University of Melbourne \t\t\t\t\t                                       Melbourne, VIC\n",
    "            Master of Information Technology (AI major)\t                                            Jan 2022 – Nov 2023\n",
    "            WAM:                  83/100, Graduate with Distinction\n",
    "            Core Courses:     Natural Language Processing                Computer Vision\n",
    "                                Algorithm and Complexity                     Cluster and Cloud Computing\n",
    "            Awards:               Dean’s Honours List  2022  & 2023\n",
    "                                        Melbourne Graduate Scholarship 2022\n",
    "        ''',\n",
    "        'similar_job_description': f\"{similar_job_description}\"\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers={\"Content-Type\": \"application/json\"}, data=json.dumps(dummy_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': '{\\n'\n",
      "             '    \"Intro\": \"Thank you for reaching out for assistance in '\n",
      "             'improving your skills for potential job opportunities. However, '\n",
      "             'it appears that there is no specific work experience or job '\n",
      "             'descriptions provided.\",\\n'\n",
      "             '    \"Strengths\": \"Without specific experiences or job '\n",
      "             \"descriptions, it's challenging to assess particular strengths \"\n",
      "             'accurately. However, everyone has inherent strengths such as '\n",
      "             'motivation, willingness to learn, and adaptability that can be '\n",
      "             'valuable.\",\\n'\n",
      "             '    \"Weaknesses\": \"The absence of documented work experience '\n",
      "             'might be a weakness in the job market. Not having job '\n",
      "             'descriptions to compare against also limits the ability to '\n",
      "             'identify specific skill gaps.\",\\n'\n",
      "             '    \"Suggestions for Improvement\": \"1. **Gain Experience**: '\n",
      "             'Engage in internships, volunteer work, or part-time jobs to '\n",
      "             'build a work history. \\\\n2. **Education and Training**: Consider '\n",
      "             'enrolling in courses related to your field of interest. Online '\n",
      "             'platforms like Coursera, Udemy, or LinkedIn Learning can be '\n",
      "             'helpful. \\\\n3. **Networking**: Join professional networks, '\n",
      "             'attend industry conferences, and participate in online forums to '\n",
      "             'meet professionals in your desired field. \\\\n4. **Skill '\n",
      "             'Development**: Focus on transferable skills like communication, '\n",
      "             'teamwork, and problem-solving, which are valuable in any job. '\n",
      "             '\\\\n5. **Career Counseling**: Seek guidance from career advisors '\n",
      "             'or mentors to help identify areas of interest and potential '\n",
      "             'career paths.\",\\n'\n",
      "             '    \"Conclusion\": \"Even though there is no specific information '\n",
      "             'provided, these general suggestions can help you build a '\n",
      "             'foundation to better position yourself for future job '\n",
      "             'opportunities. As you gain more experiences and identify job '\n",
      "             'interests, you can further refine your skills and resume.\"\\n'\n",
      "             '}'}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(response.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
